---
execute:
  eval: false

engine: knitr
---

# Workflow to analyse MicEco 2025 data

## Project description

Different combinations of microbial strains were mixed to test their interactions in liquid culture. After growth, DNA was isolated, the full-length 16S rRNA gene amplified and sequenced using Nanopore sequencing. The goal of this workflow is to:

- Assess the quality of sequence reads
- Perform quality cleaning
- Map the filtered read to a reference 16S database 
- Generate a count table

Sample info:

tba

## Dependencies

Analyses were executed on AlmaLinux 8.10 (x86_64), that info was extracted via `uname -a` and `cat /etc/os-release`. The used software is:

- sed (GNU sed) 4.5
- seqkit v2.7.0
- nanoplot v1.42.0
- chopper v0.11.0
- minimap2 2.22-r1105-dirty
- Custom scripts that are available [via github](https://github.com/ndombrowski/MicEco2025/tree/refs/heads/main/scripts)
    - combine_nanoplot_html.py
    - paf_to_matrix.py
    - Dependencies: Python 3.10.18, pandas v2.3.0, matplotlib v3.9.2 (determined via `pip show package`)


## Project setup

Data was analysed on the Uva Crunchomics HPC:

```{bash}
# Define project directory
wdir="/home/ndombro/personal/miceco2025_da"
cd $wdir
```



## Prepare input files

We work with the following data:

- Sequencing data was provided as zipped folder called `Microbiocourse2025.zip` by Peter Kuperus Oktober 22, 2026 via SurfDrive and stored in the data folder 
- The file `filelists/barcode_to_sample` was generated manually from the mapping file provided by Peter Kuperus and links the barcode to a sample ID.

To analyse the data, individual files per sample were first combined into a single file.

```{bash}
mkdir -p data/combined scripts results filelists logs

# Prepare the raw data for further analysis
unzip data/Microbiocourse2025.zip -d data

# List all barcodes: n = 15 samples
# Used this as template to generate filelists/barcode_to_sample in nano
ls data/Microbiocourse2025/fastq_pass/barcode*/*fastq.gz | \
    grep -Eo "/barcode[0-9]+/" | \
    sort  -u | sed 's/\///g' > filelists/barcodes.txt

wc -l filelists/barcodes.txt

# Combine individual fastq files per barcode/sample into 15 new files
for i in `cat filelists/barcodes.txt`; do 
    echo "Combine files for $i"
    cat data/Microbiocourse2025/fastq_pass/${i}/*.fastq.gz > data/combined/${i}.fastq.gz
done

ll data/combined/* | wc -l
ll -h data/combined
```


## Assess read quality 

```{bash}
mkdir -p results/seqkit results/nanoplot/raw 

# Run seqkit 
srun --cpus-per-task 10 --mem=50G seqkit stats \
    -a -To results/seqkit/seqkit_raw.tsv data/combined/*fastq.gz --threads 10

# Run Nanoplot (run on login node with fewer resources in order to generate pngs)
conda activate nanoplot_1.42.0

for file in data/combined/*fastq.gz; do
    barcode=$(basename $file .fastq.gz)
    echo "Start analysis for $barcode"

    srun --cpus-per-task 6 --mem=10G NanoPlot \
        --fastq ${file} \
        -t 6 \
        --tsv_stats \
        --plots dot \
        -o results/nanoplot/raw/${barcode}
done

conda deactivate

## Combine Nanoplot HTMLs into one document
python scripts/combine_nanoplot_html.py --base_path results/nanoplot/raw \
    --output_html results/nanoplot/raw_nanoplot.html --start_barcode 01 --end_barcode 15

```

Notes:

- Total number of reads is very evenly distributed, from 3400-4900 reads/sample
- The median read length (Q2) is around 1450 bp
- The phred score is around 12
- Notes from the combined Nanoplots:
    - Most reads around 1450 bp
    - Few reads that are longer, more reads that are a bit shorter
    - Phread score evenly distributed around Phred score 10-20

Settings I chose for cleaning based on the NanoPlots:

- Phred 12
- Min length 1300
- Max length 1650


### Quality reads with chopper

```{bash}
# Run chopper
conda activate chopper_0.11.0

for file in data/combined/barcode*fastq.gz; do
    barcode=$(basename "$file" .fastq.gz)
    outdir="results/chopper/" 
    mkdir -p "$outdir"

    echo "Start analysis for ${barcode}"

    srun --cpus-per-task 10 --mem=50G chopper -i "$file" \
        -q 12 \
        --trim-approach trim-by-quality --cutoff 12 \
        -l 1300 --maxlength 1650 \
        --threads 10 | gzip > "${outdir}/${barcode}.fastq.gz"
done

conda deactivate
```

Notes from this analysis (table generated by using the standard output from chopper and converting it to markdown via chatgpt):

| barcode   | input_reads | output_reads | perc_kept |
| --------- | ----------- | ------------ | --------- |
| barcode01 | 3835        | 1957         | 51.0%     |
| barcode02 | 3725        | 1950         | 52.3%     |
| barcode03 | 3892        | 1976         | 50.8%     |
| barcode04 | 4346        | 2274         | 52.3%     |
| barcode05 | 3497        | 1872         | 53.5%     |
| barcode06 | 3422        | 1749         | 51.1%     |
| barcode07 | 3785        | 1883         | 49.8%     |
| barcode08 | 3613        | 1923         | 53.2%     |
| barcode09 | 3546        | 1814         | 51.2%     |
| barcode10 | 3937        | 2073         | 52.7%     |
| barcode11 | 4366        | 2306         | 52.8%     |
| barcode12 | 4386        | 2251         | 51.3%     |
| barcode13 | 4239        | 2182         | 51.5%     |
| barcode14 | 4927        | 2587         | 52.5%     |
| barcode15 | 4681        | 2427         | 51.8%     |

: {.striped .responsive .sm}


### Check quality of the cleaned data

```{bash}
# Get overaching summary with seqkit and summarize with awk
srun --cpus-per-task=10 --mem=5G seqkit stats results/chopper/*fastq.gz  \
    -Tao results/seqkit/fastq_filtered.tsv --threads 10

```

- Total number of reads is very evenly distributed, from 1700-2600 reads/sample
- The median read length (Q2) is around 1450 bp
- The phred score is around 13.5


### Read mapping 

The reference sequences were generated as is discussed in `source/analysis_test_data.qmd`. Note that the file `amplicons_nr_final.fasta` that is mentioned in this workflow was named `amplicons_nr.fasta` but both are the same files.

```{bash}
mkdir results/mapping_counts results/tables

# Get reference database and accession to genus mapping file
wget https://raw.githubusercontent.com/ndombrowski/MicEco2025/refs/heads/main/data/amplicons_nr.fasta -P data
wget https://raw.githubusercontent.com/ndombrowski/MicEco2025/refs/heads/main/data/accession_to_genus.tsv -P data

# Run minimap 
for file in results/chopper/barcode*.fastq.gz; do
    ref_db="data/amplicons_nr.fasta"
    barcode=$(basename $file .fastq.gz)
    
    echo "----------------------------------------------------------------"
    echo "Mapping $barcode to reference database..."
    echo "----------------------------------------------------------------"

    # Map reads to reference and save PAF
    srun --cpus-per-task 2 --mem=20G minimap2 \
        -cx map-ont -t 2 ${ref_db} ${file} \
        > results/mapping_counts/${barcode}.paf
done

# Generate count table 
python scripts/paf_to_matrix.py \
    -i results/mapping_counts/ \
    -o results/tables/ \
    -t data/accession_to_genus.tsv \
    -s results/seqkit/fastq_filtered.tsv

```

Notes: 

- More reads removed in barcode01-barcode06 --> likely due to Pseudomonas multi-mappers that had a low mapping quality
- Also note that these samples still had many more matches than reads even after quality filtering
- To control the counts, I opened `otu_table_genus.tsv` in excel to calculate the total counts/sample and these corresponded to the total counts after chopper that are shown above

```
Per-sample filtering summary:
           before  after  removed  removed_frac_perc
sample
barcode01    5799   5041      758          13.071219
barcode02    5795   5044      751          12.959448
barcode03    5898   5124      774          13.123093
barcode04    6764   5373     1391          20.564755
barcode05    5555   4409     1146          20.630063
barcode06    5201   4114     1087          20.899827
barcode07    1950   1904       46           2.358974
barcode08    1980   1940       40           2.020202
barcode09    1878   1829       49           2.609159
barcode10    2140   2091       49           2.289720
barcode11    2345   2301       44           1.876333
barcode12    2316   2257       59           2.547496
barcode13    2195   2120       75           3.416856
barcode14    2604   2504      100           3.840246
barcode15    2443   2370       73           2.988129
```

OTU table without multi-mappers summarized on genus rank:

| genus             | barcode01 | barcode02 | barcode03 | barcode04 | barcode05 | barcode06 | barcode07 | barcode08 | barcode09 | barcode10 | barcode11 | barcode12 | barcode13 | barcode14 | barcode15 |
| ----------------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- | --------- |
| Flavobacterium    | 33        | 14        | 11        | 21        | 27        | 19        | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         |
| Lactobacillus     | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 1         | 0         | 0         | 1         |
| Lactococcus       | 0         | 0         | 0         | 1         | 0         | 0         | 193       | 141       | 181       | 188       | 108       | 183       | 2117      | 2497      | 2369      |
| Microbacterium    | 0         | 0         | 0         | 2         | 1         | 1         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         |
| Pseudomonas       | 1913      | 1922      | 1956      | 2234      | 1833      | 1723      | 0         | 0         | 0         | 0         | 0         | 0         | 1         | 0         | 0         |
| Pseudoxanthomonas | 1         | 7         | 1         | 3         | 4         | 2         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         | 0         |
| Streptococcus     | 0         | 0         | 0         | 0         | 0         | 0         | 1675      | 1771      | 1618      | 1864      | 2174      | 2041      | 0         | 6         | 0         |
| unassigned        | 10        | 7         | 8         | 13        | 7         | 4         | 15        | 11        | 15        | 21        | 24        | 26        | 64        | 84        | 57        |

: {.striped .responsive .sm}

The table above was generated by opening `otu_table_genus.tsv` in excel and converting input to markdown using [tabletomarkdown.com](https://tabletomarkdown.com).


## Analyse count table 

For this analysis, ``otu_table_genus.tsv` was moved into `../data/` in order to interactively analyse the data inside this notebool

### Read in the data

```{r}
library(tidyverse)

df_wide <- read_tsv("data/otu_table_genus.tsv")
mapping <- read_csv("data/barcode_to_sample.csv")
expected <- read_csv("data/expected.csv")
```

### Data wrangling

```{r}
df <- df_wide |>
    pivot_longer(
        cols = starts_with("barcode"),
        names_to = "barcode",
        values_to = "counts"
    )

df <- merge(df, mapping, by = "barcode")

df <- df |>
    separate(sample, into = c("culture", "replicate"), sep = "_", remove = FALSE) |>
    mutate(
        environment = case_when(
            startsWith(culture, "H") ~ "human",
            startsWith(culture, "S") ~ "soil"
        )
    )

df <- df |> 
    group_by(sample) |>
    mutate(rel_abundance = (counts / sum(counts)) * 100) |>
    ungroup() |>
    mutate(genus = fct_reorder(genus, rel_abundance, .fun = sum)) |>
    mutate(genus = fct_relevel(genus, "unassigned", after = 0))

df_filtered <- df |>
    inner_join(expected, by = c("culture", "genus")) |>
    group_by(sample) |>
    mutate(rel_abundance = (counts / sum(counts)) * 100) 

head(df)
```


### Plotting

```{r}
p <- ggplot(df_filtered, aes(x = sample, y = rel_abundance, fill = genus)) +
    geom_col(width = 0.95) +
    scale_fill_brewer(palette = "Dark2", direction = -1) +
    scale_y_continuous(expand = expansion(mult = c(0, 0.05)) ) +
    labs(
        y = "Relative abundance (%)",
        x = "",
        fill = "Genus"
    ) +
    facet_grid(~environment + culture, scales = "free") +
    theme_classic()   

p
```