---
engine: knitr
---

# Navigating the command line

## `pwd`: Find out where we are

Once your terminal is open, let’s get oriented by typing your first command: 

```{bash}
pwd
```

The command `pwd` stands for **print working directory**. It tells you where you currently are in the file system — that is, which folder (directory) your shell is “looking at” right now. You should see something like:

```
/Users/YourUserName
```

::: {.callout-tip title="Tip: Finding the Desktop on Different Systems" collapse="true"}
Your home directory path varies slightly across operating systems. Here’s how to locate yourself and connect to familiar locations like the Desktop:

**macOS**

-   Your home directory is `/Users/YourUserName`
-   To open the folder you are currently in Finder:`open .`
-   Your desktop is at `/Users/YourUserName/Desktop`

**MobaXterm (Windows)**

-   Your home directory is `/home/mobaxterm`
-   By default, this is temporary and is deleted when you close MobaXterm. To make it permanent:
    -   Go to Settings --\> Configuration --\> General
    -   Under Persistent home directory, choose a folder of your choice
-   To open the folder you are currently in the Windows File explorer: `explorer.exe .`
-   Your Desktop is usually at: `/mnt/c/Users/YourUserName/Desktop` or `/mnt/c/Users/YourUserName/OneDrive/Desktop` (when using OneDrive)

**WSL2 (Windows)**

-   Your home directory is`/home/YourUserName`
-   To open the folder you are currently in the Windows File explorer: `explorer.exe .`
-   Your Desktop is usually at: `/mnt/c/Users/YourUserName/Desktop` or `/mnt/c/Users/YourUserName/OneDrive/Desktop` (when using OneDrive)


If you want to access the Uva OneDrive folder:

If your OneDrive folder name includes spaces (like OneDrive - UvA), use quotes around the path: 

```{bash}
cd "/mnt/c/Users/YourUserName/OneDrive - UvA"
```

:::


## `ls`: List the contents of a directory

Now that we know where we are, let's find out what is inside that location. The command `ls` (short for *list*) shows the files and folders in your current directory. Type the following and press enter:

```{bash}
ls
```

You should see something like this (your output will vary depending on what’s in your directory):

![](../img/ls.png)

The colors and formatting depend on your terminal settings, but typically:

- Folders (directories) appear in one color (often green or blue)
- Files appear in another (often white or bold)

If your directory contains many items, the output can quickly become overwhelming. To make sense of it, we can use options and arguments to control how commands behave.


## The structure of a command

A command generally has three parts:

- A command: The program you want to run, i.e. `ls`
- An option (or flag): A way to modify how the command behaves, i.e `-l` (long format)
- An optional argument: The input, i.e. a file or folder

![](../img/unix_command.png){width=80%}

Try the following command in your current directory to "List (ls) the contents of the current folder and show details in long format (-l)":

```{bash}
ls -l
```

After running this you should see a more detail list of the contents of your folder.In the example below we can see that we now print additional information about who owns the files (i.e. access modes), how large the files are, when they were last modified and of course the name:

![](../img/ls2.png)



## Getting help

At some point, you’ll want to know what options a command has or how it works. In this case, you can always check the **manual pages** (or *man pages*). Try this:

```{bash}
man ls
```

This opens the manual entry for the command ls. You can scroll through it using:

- ↑ / ↓ arrows or the space bar to move down,
- b to move back up,
- q to quit the manual.

Not all commands use man. Depending on the program, there are a few common patterns you can try

-   `man ls`
-   `ls --help`
-   `ls -h`

For complex software, like bioinformatics tools, the most helpful documentation is often:

- The tool’s official website or GitHub repository
- The --help output that lists all parameters and examples


## `mkdir`: Make a new folder

Before we start moving around, let's first learn how to create new folders (also called directories).This is something we will do often, for example, to keep raw data, results, and scripts organized in separate places. The command we use for that is `mkdir`, which stands for *make directory*.

For now, we will use `mkdir` to create a shared working folder for this tutorial. Don’t worry about how to move into the folder yet — we’ll cover that in a bit.

```{bash}
# Move into the home directory (the starting point of your system)
cd ~

# Create a new folder called 'data_analysis'
mkdir data_analysis

# Check that the folder was created successfully
ls
```

You should see a new folder called data_analysis appear in the list. We will use this folder as our project space for all exercises in this tutorial. You can easily make a new `data` folder inside this folder by typing the following:

```{bash}
# Make a data folder inside the data_analysis folder
mkdir data_analysis/data

# Confirm that this works
# Notice here, how we use ls not with a flag but with an optional argument?
ls data_analysis
```


::: {.callout-tip title="Tip: Commenting your code" collapse="true"}
Notice how we added # and some notes above each command?

Anything written after # in Bash is a comment — it won’t be executed, but it helps you (and others) understand what the command does.

In your own work, add short, meaningful comments above key steps.
Avoid restating the obvious — instead, explain why you’re doing something or what it achieves.
:::


## `cd`: Move around folders

Now that we have our own project folder, let’s learn how to move around the file system.

The file system is structured like a tree that starts from a single root directory (that is also denoted as `/` in bash). All other folders branch out from this root directory.

![](../img/filesystem.png)

There are two ways to specify a path:

- Absolute path: starts from the root (e.g. `/Users/John/Documents`)
- Relative path: starts from your current location (e.g. `Documents` if you’re already in `/Users/John`)

Let’s practice moving between folders (at each step, use `pwd` in case you feel that you get lost):

```{bash}
# Move into the data analysis folder 
cd data_analysis 

# Check where we are 
pwd
```

We now should see that we are in something like `/Users/Name/data_analysis`. We can use the `cd` command in multiple ways:

```{bash}
# Move into the data folder
cd data

# Move one level up, i.e. go back to the data_analysis folder
cd ..

# Move multiple levels at once
cd data_analysis/data

# Quickly go back home
cd ~

# And go back to the data_analysis folder 
cd data_analysis
```

In the code above, the tilde symbol (`~`) is a shortcut for your home directory. It’s equivalent to typing the full absolute path to your home (e.g. `/Users/YourName`) but it is much faster to type.


::: {.callout-tip title="Tip: Command-line completion" collapse="true"}
Some tips for faster navigation:

- Use Tab for autocompletion — type the first few letters of a folder name and press Tab.
- If there’s more than one match, press Tab twice to see all options.
- Use ↑ / ↓ arrows to scroll through previously entered commands
:::


::: {.callout-caution collapse="false" title="Exercise"}

- Create a new folder inside your data_analysis directory called results
- Move into that folder and confirm your location with pwd
- Move back to data_analysis using `cd`
- Use `ls` to confirm both results and data are there

:::


## `wget`: Download data

Next, let’s download a genome fasta file to go through some other useful commands. We’ll use the `wget` command to fetch a file `barcode01_merged.fastq.gz` from the NCBI database:

```{bash}
# Download the example fasta into the current directory
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz
```

After you download data, it is always a good idea to do some sanity check to see if the file is present and check how large it is:

```{bash}
# List files in long (-l) and human-readable (-h) format
# combining these two commands becomes -lh
ls -lh GCF_000005845.2_ASM584v2_genomic.fna.gz
```


## `cp`: Copy files

`cp` duplicates files or directories. Let's use it to copy the downloaded file into `data`:

```{bash}
# Copy file into data 
cp GCF_000005845.2_ASM584v2_genomic.fna.gz data/

# Show content of both locations
ls -l
ls -l data
```

When running the two `ls` commands, we see that we now have two copies of `GCF_000005845.2_ASM584v2_genomic.fna.gz`, one file is in our working directory and the other one is in our data folder. Having large files in multiple locations is generally not ideal since we will use unneccassary space. However, we can use another command to move the tar folder into our data folder.


## `mv`: Move (or rename) files

`mv` moves or renames files without creating a second copy:

```{bash}
# Move the file into data
mv GCF_000005845.2_ASM584v2_genomic.fna.gz data/

# Verify
ls -l
ls -l data
```

Notice that `mv` will move a file and, without asking, overwrite the existing genome file we had in the data folder when we ran `cp`. This means for you that if you run `mv` its best to make sure that you do not overwrite files by mistake.



## `rm`: Remove files and directories

To remove files and folders, we use the `rm` command. We want to remove the `GCF_000005845.2_ASM584v2_genomic.fna.gz` file since we do not need two copies:

```{bash}
# Remove a file
rm data/GCF_000005845.2_ASM584v2_genomic.fna.gz

# Check if that worked
ls -l data
```

If we want to remove a folder, we need to tell `rm` that we want to remove folders using an option. To do this, we use `-r` , which allows us to remove directories and their contents recursively.

::: callout-important
**Unix does not have an undelete command.**

This means that if you delete something with rm, it's gone. Therefore, use `rm` with care and check what you write twice before pressing enter!
Also, NEVER run `rm -rf` on the root `/` folder or any important path. Always double check the path or file name before pressing enter.
:::




## `gzip`: (Un)compressing files

You might have noticed that the file we downloaded ends with `.gz`. This extension is used for files that are compressed to make the file smaller. This is useful for saving files, but this makes the file unreadable for a human. To be able to learn how to read the content of a file, let's uncompress the file first.

```{bash}
# Download the genome again 
# Here, we use the -P option to directly download the file into the data folder 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz -P data

# Check that this worked 
ls data

# Uncompress the file with gzip 
# Here, we use -d to decompress the file (by default gzip will compress a file)
gzip -d data/GCF_000005845.2_ASM584v2_genomic.fna.gz 

# Check that this worked 
ls data
```


## `zcat`: Decompress and print to screen

`gzip` will decompress the file and allows us to read the content of the fasta file. This is perfect for large files, but not ideal sequence data files since these files get rather larger and we might not want to decompress these files as they would clutter our system.

Luckily, there is one useful tool in bash to decompress the file and print the content to the screen called `zcat` which will print the content of a file to the screen but leave the file as is.

```{bash}
# Download another file to see how zcat works 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/016/864/595/GCF_016864595.1_ASM1686459v1/GCF_016864595.1_ASM1686459v1_genomic.fna.gz -P data 

# Check the content of the data folder 
# We should have one compressed and one uncompressed file 
ls data

# Use zcat on the compressed file 
zcat data/GCF_016864595.1_ASM1686459v1_genomic.fna.gz

# Check the content of the data folder 
# We still should have one compressed and one uncompressed file 
ls data
```


## Exploring file contents

There are different ways, to explore the content of a file, below you find the most common options.


### `cat`: Print the full file

We can use `cat` print the entire file to the screen — fine for short files, but overwhelming for long ones, which for our file is the case as we will see the nucleotides just running across the screen.

```{bash}
cat data/GCF_000005845.2_ASM584v2_genomic.fna
```


### `head` and `tail`: View parts of a file

To only print the first few or last few lines we can use the `head` and `tail` command, respectively:

```{bash}
# Show the first 10 lines (default)
head data/GCF_000005845.2_ASM584v2_genomic.fna

# Show the last 5 lines
# Here, the option -n allows us to control how many lines get printed
tail -n 5 data/GCF_000005845.2_ASM584v2_genomic.fna
```


### `less`: View the full file

`less` let's you view a file's contents one screen at a time. This is useful when dealing with a large text file (such as a sequence data file) because it doesn't load the entire file but accesses it page by page, resulting in fast loading speeds.

```{bash}
less -S data/GCF_000005845.2_ASM584v2_genomic.fna
```

-   You can use the arrow Up and Page arrow keys to move through the text file
-   To exit less, type `q`


::: {.callout-tip title="Tip: Editing text files" collapse="true"}
You can also edit the content of a text file and there are different programs available to do this on the command line, the most commonly used tool is `nano`, which should come with most command line interpreters. You can open any file as follows:

```{bash}
nano data/GCF_000005845.2_ASM584v2_genomic.fna
```

Once the document is open you can edit it however you want and then

-   Close the document with `control + X`
-   Type `y` to save changes and press enter
:::



## `wc`: Count things

Another useful tool is the `wc` (= wordcount) command that allows us to count the number of lines via `-l` in a file. It is an useful tool for sanity checking and here allows us to count how many lines of text are found in the text document.

```{bash}
wc -l data/GCF_000005845.2_ASM584v2_genomic.fna
```

We see that this file does contain 58,022 lines of text. For fasta files this is not very informative, but once you have a dataframe with rows and columns where you filter rows using certain conditions this can become very useful for sanity checking.



## `grep` : print lines that match patterns

The `grep` command searches for patterns in a file. We could for example use this to ask how often a specific nucleotide motif occurs in our fasta file.

```{bash}
grep "CATGAAACGCA" data/GCF_000005845.2_ASM584v2_genomic.fna
```

We see, highlighted in red, where we find the pattern in the nucleotide sequence. If we simply are interested in the number of files that match our pattern, we could add the option -c to count how often the pattern we search for occurs:

```{bash}
grep -c "CATGAAACGCA" data/GCF_000005845.2_ASM584v2_genomic.fna
```


## Pipes 

So far, we’ve run one command at a time — for example, using wc -l to count lines or head to look at the first few lines. But often, you’ll want to combine commands so that the output of one becomes the input of another. That’s what the pipe (`|`) does.

```{bash}
# Example: show only the first 10 lines and count how many lines of text that is
head -n 100 data/GCF_000005845.2_ASM584v2_genomic.fna | grep -c "CATGAAACGCA" 
```

Here:

- `head -n 100 data/GCF_000005845.2_ASM584v2_genomic.fna` prints the first 100 lines
- The pipe (`|`) sends these 100 lines directly to the `grep` command
- `grep -c "CATGAAACGCA"` only counts how often the nucleotide motif occurs in the first 100 lines of the fasta file



## Working with multiple files

So far, we’ve worked with single files. In practice, sequencing data often comes as multiple files — for example, one FASTQ file per barcode. Let’s practice handling several files at once. Let's begin by getting more genomes!

```{bash}
# Download more data 
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/813/895/GCA_002813895.1_ASM281389v1/GCA_002813895.1_ASM281389v1_genomic.fna.gz -P data
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/813/895/GCA_002813895.1_ASM281389v1/GCA_002813895.1_ASM281389v1_protein.faa.gz -P data

wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/317/675/GCF_000317675.1_ASM31767v1/GCF_000317675.1_ASM31767v1_genomic.fna.gz -P data
wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/317/675/GCF_000317675.1_ASM31767v1/GCF_000317675.1_ASM31767v1_protein.faa.gz -P data

# Check what was done
ls -lh data
```

We now should have 6 files, 5 of which are still compressed. Notice, how there are some slight differences:

- The file names start with either GCA or GCF indicating that they come from the GenBank versus RefSeq database
- The file names end with either fna.gz or faa.gz indicating that the contain nucleotide versus protein sequences


::: {.callout-tip title="Hint: Downloading many files with a for loop" collapse="true"}
Once you understand how to use `wget`, you can easily scale it up to download multiple files automatically using a simple **for loop**.

For example, suppose you have a list of NCBI genome URLs stored in a file called `urls.txt` — one per line:

```
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/005/845/GCF_000005845.2_ASM584v2/GCF_000005845.2_ASM584v2_genomic.fna.gz
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCA/002/813/895/GCA_002813895.1_ASM281389v1/GCA_002813895.1_ASM281389v1_protein.faa.gz 
```

You can then loop through all URLs and download them into the `data` folder like this:

```{bash}
for url in $(cat urls.txt); do
    wget "$url"
done
```

Here’s what happens:

- `$(cat urls.txt)` reads all lines from the file
- `for url in ...` goes through each line one by one
- `wget data "$url"` downloads each genome into the current folder

A more detailed explanation about for-loops can be found [here](https://scienceparkstudygroup.github.io/ibed-bioinformatics-page/source/core_tools/bash-for-loops.html).

:::


### Wildcards (`*`): Match multiple files

Imagine we want to uncompress all the new files. Typing every filename can get tedious. **Wildcards** help you work with groups of files using pattern matching.

```{bash}
# List all files inside the data folder that end with gz
ls data/*gz

# List all protein fasta files inside the data folder 
# using `*faa*` means we look for filenames that contain a faa inside the name and that we allow for characters before and after
ls data/*faa*

# If we would not add a asterisk after the faa we do not get any files, because none of the files end with faa
ls data/*faa
```

We can use Wildcards with every bash command and use it to unzip every file at once with:

```{bash}
gzip -d data/*gz

# Check if that worked
ls -lh data
```


### `cat`: Combining files 

The cat command doesn’t just print files — it can also concatenate (join) multiple files into one. For example, if you have several protein files and want to merge them:

```{bash}
# Combine the protein fasta files into one
cat data/*faa > proteins.faa
```

Here:

- `data/*faa  `selects all files in the data folder that end with faa
- `>` tells the shell to write the combined output into a new file called proteins.faa


::: {.callout-caution title="Important: Be careful with >" collapse="false"}
The `>` operator overwrites files without asking.
If you want to add (append) to an existing file instead of replacing it, use `>>`:
:::

Whenever you modify files it is a good idea to do some sanity checks. Luckily, we already learned about useful ways to do this:


```{bash}
# Check how many protein files are in the individual faa files 
grep -c ">" data/*faa

# Check how many protein files are in concatenated file
# Hopefully the numbers add up
grep -c ">" proteins.faa
```