---
execute:
  eval: false
engine: knitr

---

# Amplicon long-read analysis

Sections that are still in progress:

- Work on sections quality cleaning (consider testing fastplong), consensus generation (ngspeciesID), blast for taxonomic assignment and minimap for counts --> will be added to Chapter 6 (From raw reads to results)


## `fastplong`: Quality cleaning 

In this section, you will learn how to perform quality filtering and adapter trimming of your amplicon long-read data using fastplong. Quality control is an essential first step to ensure that only high-quality reads are used for downstream analyses such as consensus generation and taxonomic assignment.

You can install fastplong with mamba:

```{bash}
mamba create -p fastplong_0.4.1 -c bioconda fastplong=0.4.1
```

In this tutorial, you will always receive example code as a starting point, with sections containing `...` for you to fill in. If you get stuck, check [the tools official documentation](https://github.com/OpenGene/fastplong) or use the built-in help via the CLI (`fastplong -h`).

::: {.callout-question .callout-warning collapse=false}
# Task 

Use your NanoPlot quality plots from the previous section and choose some quality and length cutoffs. Specifically, you want to:

- Store the output of fastplong in a separate results folder 
- Request 2 CPUs with `srun`, and ensure fastplong also uses 2 threads
- Discard sequences that are too long or too short
- Discard reads, where the read's average quality score is lower than a quality score of Q8.
- Move a sliding window from front (5') to tail, drop the bases in the window if its mean quality < Q8

```{bash}
# Generate an output folder for the results
... 

# Activate the fastplong conda environment
...

# Run fastplong
srun --mem=20G --cpus-per-task 2 fastplong ...

# Deactivate the conda environment 
...
```

After the analysis finished check the output and record:

- The total number of sequences that went into the analysis
- The total number of sequences that passed the quality filtering
- At which step most reads were lost (and how many)
- How many basepairs were lost due to the trimming


::: {.callout-answer .callout-warning collapse=true}
# Click to see the answer 

```{bash}
# Generate an output folder for the results
mkdir results/fastplong

# Activate the fastplong conda environment
conda activate fastplong_0.4.1

# Run fastplong
srun --mem=20G --cpus-per-task 2 fastplong \
    -i data/barcode01_merged.fastq.gz \
    -l 1400 --length_limit 1700 \
    --mean_qual 8 --cut_front 8 \
    --thread 2 \
    -o results/fastplong/barcode01_filtered.fastq.gz

# Deactivate the conda environment 
conda deactivate
```

**Parameter overview:**
- `--mean_qual 8`: Removes reads with an average Phred quality below 8
- `-l 1400 --length_limit 1700`: Keeps reads roughly within the expected amplicon size range
- `--cut_front 8`: Removes low-quality bases using a sliding window approach
- `--thread 2`: Uses two CPU threads for parallel processing


Below are example results from one of my analyses. These numbers will be different for you, however, this process will make you more familiar for what to look for in your own analyses.

- Input: 17,121 reads
- Passed filtering: 8,433 reads (49%). For my data this is reasonable given the left-tail seen in the NanoPlot quality plot
- Most reads were lost because they were too short (4,627) or had low quality (4,084)
- The dataset initially contained 24,089,162 bp, of which 12,339,313 bp (~51%) were retained

:::
:::