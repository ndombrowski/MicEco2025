---
execute:
  eval: false
engine: knitr

---

# Amplicon long-read analysis

Sections that are still in progress:

- Work on sections quality cleaning (consider testing fastplong), consensus generation (ngspeciesID), blast for taxonomic assignment and minimap for counts --> will be added to Chapter 6 (From raw reads to results)


## `chopper`: Quality cleaning 

In this section, you will learn how to perform quality filtering of your amplicon long-read data using chopper. Quality control is an essential first step to remove low quality reads that introduce errors in downstream analyses such as consensus generation and taxonomic assignment. Typical things you want to do are:

- Removing sequence adapters, barcodes, primer sequences. This already has been done for your data.
- Removing reads with a too low quality score
- Removing reads that are too long or too short
- Trimming read ends if they have low quality scores

`chopper` is designed for filtering and trimming of long-read data and you can install `chopper` with mamba:

```{bash}
mamba create -n chopper_0.11.0 -c bioconda chopper=0.11.0
```

In this tutorial, you will always receive example code as a starting point, with sections containing `...` for you to fill in. If you get stuck, check [chopper's documentation](https://github.com/wdecoster/chopper) or use the built-in help via the CLI (`chopper -h`).

::: {.callout-question .callout-warning collapse=false}
# Tasks 

Use your NanoPlot quality plots from the previous section and choose some quality and length cutoffs. Specifically, you want to:

1. Perform quality filtering with chopper:
    - Store the output of chopper in a separate results folder
    - Request 2 CPUs and 20G of memory with `srun`, and ensure chopper itself also uses 2 threads
    - Discard sequences that are too long or too short
    - Discard reads, where the read's average quality score is lower than a quality score of Q15
    - Check the [tools manual](https://github.com/wdecoster/chopper) carefully with how to deal with `.gz` files. Hint: Closely check the example section
2. Investigate the quality of the filtered FASTQ file with NanoPlot 
    - use srun, 2 CPUs and 10G of memory
3. afterwards open NanoPlots LengthvsQualityScatterPlot_dot.html and NanoStats.txt outputs and answer:
    - The total number of sequences that went into the analysis
    - The total number of sequences that passed the quality filtering
    - At which step most reads were lost (and how many)
    - How many basepairs were lost due to the trimming

```{bash}
# Generate an output folder for the results
... 

# Activate the chopper conda environment
...

# Run chopper
srun --cpus-per-task 2 --mem=20G chopper ...

# Deactivate the conda environment 
...

# Make a folder for the Nanoplot results and run Nanoplot
...
```


::: {.callout-answer .callout-warning collapse=true}
# Click to see the answer 

```{bash}
# Generate an output folder for the results
mkdir results/chopper

# Activate the chopper conda environment
conda activate chopper_0.11.0

# Run chopper
srun --cpus-per-task 2 --mem=20G chopper \
    -i data/barcodeX.fastq.gz \
    -q 16 \
    --minlength 1300 --maxlength 1600 \
    --threads 2 | gzip \
    > results/chopper/barcodeX_filtered.fastq.gz

# Deactivate the conda environment 
conda deactivate

# Run Nanoplot
conda activate nanoplot

mkdir -p results/nanoplot/cleaned

srun --cpus-per-task 2 --mem=10G NanoPlot \
    --fastq results/chopper/barcodeX_filtered.fastq.gz \
    -t 2 \
    --tsv_stats \
    --plots dot \
    -o results/nanoplot/cleaned

conda deactivate
```

Below are example results from one of my analyses. These numbers will be different for you, however, this process will make you more familiar for what to look for in your own analyses.

- Input: 43,170 reads
- Passed filtering: 28665 reads (66%). For this data this is reasonable given the relatively high Phred score we use for quality filtering


:::
:::



## `NGSpeciesID`: Read clustering 

Nanopore long-read sequencing can produce reads that span nearly the entire 16S rRNA gene, making it powerful for identifying microbial species. However, these long reads come with a trade-off: they have a higher error rate compared to short-read technologies.

In our dataset, the average read quality is Q15. The Phred score (Q) is a measure of how confident the sequencer is in each base call. The probability of a base being called incorrectly can be calculated as:

$$P=10^{-Q/10}$$

In R we can compute this with:

```{r}
#| eval: true
Q <- 16
P_error <- 10^(-Q/10)
percent_error <- P_error * 100
message("Error rate: ", round(percent_error, 2), "%")
```

This shows that with a mean Phred quality of 15, each base has roughly a 2.5% chance of being incorrect. Across a 1,500 bp amplicon, that’s about 38 errors per sequence, which can be too many for accurate species-level identification.

To address this, we can cluster similar reads together, meaning we group sequences that likely come from the same species. Tools like NGSpeciesID cluster reads and then build a consensus sequence for each cluster, correcting random sequencing errors by comparing all reads within a cluster. 

You can install NGSpeciesID with mamba:

```{bash}
# Create a base environment
mamba create -n NGSpeciesID_0.3.1  python=3.11 pip

# Activate and install dependencies
conda activate NGSpeciesID_0.3.1
mamba install --yes -c conda-forge -c bioconda medaka==2.0.1 openblas==0.3.3 spoa racon minimap2  samtools
pip install NGSpeciesID
conda deactivate
```


::: {.callout-question .callout-warning collapse=false}
# Task 

Familiarize yourself with the [NGSpeciesID documentation](https://github.com/ksahlin/NGSpeciesID) and finish the code below:

**Step1**: Prepare the input files as NGSpecies ID can not work with compressed FASTQ files.

```{bash}
# Uncompress the chopper output
...
```

**Step2**: Run NGSpeciesID

Here, you want to:

- Use srun with with 5 CPUs, 50G of memory
- Specify that you’re working with ONT data 
- Use the cleaned uncompressed FASTQ file as input
- Output results to a new results folder
- Enable consensus generation (`--consensus`) and further polishing (`--medaka`)
- Lower the abundance ratio to 0.01 (captures low-abundance sequences)
- Require reads to align at least 95% (`--aligned_threshold 0.95`)

```{bash}
# Activate the conda environment
conda activate NGSpeciesID_0.3.1

# Run NGSpeciesID
srun ... NGSpeciesID ...

# Deactivate the conda environment 
...
```

**Step3**: Explore the output

In your results folder, you should find multiple subfolders (e.g., `medaka_cl_id_*`). Each folder contains a consensus.fasta file representing a consensus sequence.

Answer the following:

- How many consensus sequences were formed?
- Is this number higher or lower than what you expected based on your experimental design (number of microbial species)?
- If it differs, what could explain this discrepancy? Hint: Think about sequencing errors, read depth, and 16S sequence similarity.

```{bash}
# How many consensus sequences are formed?
grep ...
```



::: {.callout-answer .callout-warning collapse=true}
# Click to see the answer 

The `scripts/ngspeciesid.sh` should look as follows:

```{bash}
# Uncompress the chopper output as NGSPeciesID only works with uncompressed files 
gzip -d results/chopper/barcodeX_filtered.fastq.gz

# Activate the conda environment
conda activate NGSpeciesID_0.3.1

# Run NGSpeciesID
srun --cpus-per-task 20 --mem=50G NGSpeciesID \
        --ont \
        --fastq results/chopper/barcodeX_filtered.fastq \
        --outfolder results/ngspeciesid  \
        --consensus --medaka \
        --t 20 \
        --aligned_threshold 0.95 \
        --abundance_ratio 0.01 

conda deactivate

# Count how many consensus sequences we work with
grep ">" results/ngspeciesid/medaka*/*fasta
```

Answer:

- Number of consensus sequences formed: 9
- Expected number: 14 (based on 14 bacterial strains used)
- Possible reasons for less consensus sequences:
    - The high Nanopore error rate can blur true biological differences
    - Highly similar 16S rRNA genes (95–99.9% identity) may have merged into a single cluster
    - Lower-abundance taxa may not have had enough reads to form a distinct cluster
- If you observe more consensus sequences than expected, it could indicate incomplete clustering due to sequencing errors or uneven read coverage

:::
:::